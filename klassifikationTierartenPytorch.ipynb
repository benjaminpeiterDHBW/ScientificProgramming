{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d417abd4",
   "metadata": {
    "id": "d417abd4"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "095ade79",
   "metadata": {
    "id": "095ade79"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LrWcJJ_aP7nF",
   "metadata": {
    "id": "LrWcJJ_aP7nF"
   },
   "source": [
    "# Datensätze\n",
    "**Es kann zwischen folgenden Datensätzen gewählt werden:**\n",
    "\n",
    "## 1. Animal Faces Dataset von Husaa Anwar\n",
    "Dieser Datensatz enthält Bilder von Katzen, Hunden und Wildtieren. Er ist aufgeteilt in Trainings- und Validierungsdaten.\n",
    "\n",
    "## 2. Animal Dataset von Anton Benedetti\n",
    "Auch dieses Datenet ist in Trainings- und Validierungsdaten unterteilt, behinhaltet diesmal aber Hunde, Katzen, Elefanten, Pferden und Löwen.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492cd10b",
   "metadata": {
    "id": "492cd10b"
   },
   "source": [
    "## Daten Import and Vorbereitung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4mWbvqA-SwZV",
   "metadata": {
    "id": "4mWbvqA-SwZV"
   },
   "source": [
    "Im folgenden Code werden die Datensätze heruntergeladen und importiert. Bevor diese für unser CNN bereit sind müssen wir allerdings noch ein paar Anpassungen vornehmen.\n",
    "\n",
    "1. Laden der Bilder aus Ordnerstruktur.\n",
    "  - Jeder Unterornder wird als eigene Klasse interpretiert\n",
    "\n",
    "2. Die Bilder werden auf 128 x 128 Pixel herunterskaliert.\n",
    "\n",
    "3. Konvertierung von **PIL.image** zu **torch.tensor**\n",
    "  -PIL.image sind Bildobjekte aus der Python Libary und stellen Bilder in ein für Menschen lesbares Format dar. Das ist für uns allerdings unbrauchbar, da unser Netz nur mit numerischen Werten arbeiten kann. Deswegen wandeln wir diese in **torch.Tensor** um. Das ist ein Pytorch Datentyp, der auf GPU-basiertes Training optimiert ist.\n",
    "\n",
    "4. Normalisieren der RGB-Kanäle mit Mittelwert 0.5 und Standardabweichung 0.5\n",
    "\n",
    "4. Datenloader erstellt\n",
    "  - 32 Bilder pro Batch\n",
    "  - mit zufälliger Mischung\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f681d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4f681d9",
    "outputId": "69c5f144-ba94-4592-865c-5f43899a6a05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.12)\n",
      "Path to dataset 2 files: /Users/julian.greiner/.cache/kagglehub/datasets/antobenedetti/animals/versions/5\n",
      "Classes: ['cat', 'dog', 'elephant', 'horse', 'lion']\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "#path = kagglehub.dataset_download(\"andrewmvd/animal-faces\")\n",
    "path2 = kagglehub.dataset_download(\"antobenedetti/animals\")\n",
    "\n",
    "#print(\"Path to dataset files:\", path)\n",
    "print(\"Path to dataset files:\", path2)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "#train_dataset = datasets.ImageFolder(os.path.join(path, 'afhq/train'), transform=transform)\n",
    "#val_dataset = datasets.ImageFolder(os.path.join(path, 'afhq/val'), transform=transform)\n",
    "\n",
    "train_dataset = datasets.ImageFolder(os.path.join(path2, 'animals/train'), transform=transform)\n",
    "val_dataset = datasets.ImageFolder(os.path.join(path2, 'animals/val'), transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "classes = train_dataset.classes\n",
    "print(f\"Classes: {classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51bc492",
   "metadata": {
    "id": "b51bc492"
   },
   "source": [
    "## Modellarchitektur: Convolutional Neural Network (**CNN**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3JT01FvlW7i6",
   "metadata": {
    "id": "3JT01FvlW7i6"
   },
   "source": [
    "### Aufbau des Netzwerks:\n",
    "Für die Klassifizeirung von Tierarten wurd ein Convolutional Neural Network gewählt. Diese sind besonders gut für Bildverarbeitung geeignet, da sie in der Lage sind Bildstrukturen effizient zu erfassen und Merkmalsabstraktion über Faltungsprozesse ermöglicht. Diese Faltungsprozesse sind mathematische Operationen bei denen ein kleinerer Filter über das Eingabebild geschoben werden und dann an jeder Position eine gewichtete Summe der überlappenden Pixel zu berechnen. Das Ergebnis daraus ist dann ein Merkmalbild, das bestimmte Muster sichtbar macht.\n",
    "Anfangs sind die Filter zufällig initialisiert, passen sich aber währen dem Training über \"Backpropagation\" an.\n",
    "\n",
    "---\n",
    "\n",
    "Unsere Klasse AnimalCNN erbt von torch.nn.Module und besteht aus zwei Hauptkomponenten:\n",
    "\n",
    "#### 1. Convolutional Layers (Merkmalextraktion)\n",
    "\n",
    "Hier werden zunehmend komplexere Bildmerkmale extrahiert, z.B. Kanten, Formen oder Objektteil.\n",
    "\n",
    "Faltung:\n",
    "- Kernalgröße 3x3\n",
    "-Padding 1\n",
    "\n",
    "Aktivierungsfunktion:\n",
    "- ReLU (Rectified LinearUnit) unterstützt nicht-lineare Entscheidungsgrenzen\n",
    "\n",
    "Pooling:\n",
    "- 2x2 <- zur reduktion räumlicher Dimensionen bei gleichzeitiger Erhaltung wesentlicher Merkmale\n",
    "\n",
    "\n",
    "#### 2. Fully Connected Layers (Klassifikation)\n",
    "\n",
    "Bilden den letzen Teil des CNN und übernehmen die Klassifikation auf Basis der extrahierten Merkmale. Jeder Neuron dieser Schicht ist mit allen Neuronen der vorherigen Schicht verbunden, wodurch eine gewichtete Kombination aller Merkmalsinformationen entsteht. Damit kann das Netzt entscheiden zu welcher Klasse ein Bild gehört.\n",
    "\n",
    "Flatten:\n",
    "- um in einen Vektor zu überführen\n",
    "\n",
    "Linear(...):\n",
    "- verbundene Schichten klassifizieren das extrahierte Merkmalsmuster.\n",
    "\n",
    "\n",
    "\n",
    "#### Vorwärtsdurchläufe\n",
    "Wendet Convolutional und Fully Connected Layers an\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "504a3d16",
   "metadata": {
    "id": "504a3d16"
   },
   "outputs": [],
   "source": [
    "class AnimalCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(AnimalCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 8 * 8 * 4, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5260675",
   "metadata": {
    "id": "a5260675"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2yJZsrp7f0Vx",
   "metadata": {
    "id": "2yJZsrp7f0Vx"
   },
   "source": [
    "Zuerst wird hier überprüft, welche Geräte zum Training zur Verfügung stehen und überprüft, ob sie CUDA fähig sind. CUDA fähige GPUs sind optimal, da diese sehr gut viele prozesse parrallel berechnen könne as perfekt für das Training eines Neuronalen Netz ist.\n",
    "\n",
    "Wurde ein passendes Gerät gefunden, so wird jetzt das Modell auf dieses verschoben.\n",
    "\n",
    "#### Verlustfunktion\n",
    "Es wird eine Verlustfunktion hinzugefügt, die die Differenz zwischen vorhergesagter Klassenverteilung und tatsächlichen Label errechnet.\n",
    "\n",
    "#### Optimierer\n",
    "Außerdem wird ein Optimierer hinzugefügt, der mit dem Gradientenabstieg arbeitet und eine Lernrate übergeben bekommt. Dieser wird benötigt, um das Netz je nach Verlust dem entsprechend anzupassen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa0e778d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "fa0e778d",
    "outputId": "cefd6d3b-50b1-4bbb-f1c4-7f77dae7c66b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "device2 = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else device2)\n",
    "model = AnimalCNN(num_classes=len(classes)).to(device)\n",
    "\n",
    "print(\"device:\", device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "E7wwHaZriOcr",
   "metadata": {
    "id": "E7wwHaZriOcr"
   },
   "source": [
    "## Trainingsscheife\n",
    "\n",
    "Der Trainingsprozess läuft über mehrere Epochen mit Batches trainiert, wobei jede Epoche einmal durch den gesamten Trainingsdatensatz iteriert, wodurch die Generalisierungsfähigkeit des Modells. Durch Backpropagation und dem Optimierer verbessert das Netzt seine parameter. Der Verlust wird pro Epoche dokumentiert um den Lernfortschritt einsehen zu können (mit live Anzeige).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0c3478e",
   "metadata": {
    "id": "b0c3478e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 422/422 [04:26<00:00,  1.58it/s, loss=0.468]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Average Loss: 0.8965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "    for images, labels in progress_bar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    print(f\"Epoch {epoch+1} Average Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a1e5f1",
   "metadata": {
    "id": "58a1e5f1"
   },
   "source": [
    "### Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4c508bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "c4c508bf",
    "outputId": "75c96ac5-18d1-418c-a9ae-098fa7938048"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_losses, marker='o', label='Training Loss')\n",
    "plt.title(\"Training Loss over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4fe50c",
   "metadata": {},
   "source": [
    "## 1 Visualisierung des Trainingsverlusts\n",
    "\n",
    "Der folgende Code erstellt ein Diagramm, das den Verlauf des Trainingsverlusts (`Loss`) über alle Epochen hinweg zeigt. Jeder Punkt steht dabei für den durchschnittlichen Verlust pro Epoche.\n",
    "```python\n",
    "# Neues Plot-Fenster mit einer definierten Größe\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Wir plotten die gespeicherten Trainingsverluste.\n",
    "# Die Marker \"o\" heben die einzelnen Punkte in der Linie hervor.\n",
    "plt.plot(train_losses, marker='o', label='Training Loss')\n",
    "\n",
    "# Titel für das Diagramm\n",
    "plt.title(\"Training Loss over Epochs\")\n",
    "\n",
    "# Beschriftung der X- und Y-Achsen\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "# Anzeige der Legende (in diesem Fall: \"Training Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# Ein Gitter erleichtert das Ablesen des Plots\n",
    "plt.grid(True)\n",
    "\n",
    "# Zeige das Diagramm an\n",
    "plt.show()\n",
    "```\n",
    "# Erklärung des Diagrammverlaufs\n",
    "\n",
    "Das gezeigte Diagramm stellt den Trainingsverlust dar, der während des Trainings berechnet wird.\n",
    "\n",
    "Zu Beginn des Trainings ist der Loss-Wert in der Regel sehr hoch, da das Modell noch keine sinnvollen Vorhersagen treffen kann.  \n",
    "In den ersten Epochen sinkt der Verlust schnell, weil das Modell grundlegende Muster wie Kanten oder Farben in den Bildern lernt.  \n",
    "In höheren Epochen verlangsamt sich der Abfall des Loss-Werts immer mehr, da das Netz die grundlegenden Muster bereits erlernt hat und nur durch höhere Komplexität weitere Verbesserungen erreicht werden können.\n",
    "\n",
    "Gegen Ende erreicht der Loss einen stabilen Wert, was auf eine Konvergenz des Trainings hinweist.  \n",
    "Diese typische Kurve (starker Abfall am Anfang, langsamer Abfall später, Plateau am Ende) ist ein Zeichen dafür, dass das Modell effektiv lernt und sich an die Trainingsdaten anpasst."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a23c2e",
   "metadata": {
    "id": "80a23c2e"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b12f901a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b12f901a",
    "outputId": "76d72593-9719-4414-f386-fe847e63b382"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 78.16%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fe4bdb",
   "metadata": {},
   "source": [
    "# Erklärung der Evaluierung\n",
    "\n",
    "Bei der Modell-Evaluierung wird die Leistung des trainierten Modells auf neuen, ungesehenen Daten überprüft.  \n",
    "Dazu wird der sogenannte Validierungsdatensatz genutzt, der während des Trainings nicht betrachtet wurde. Dies stellt sicher, dass das Modell nicht nur auf die Trainingsdaten passt, sondern auch auf andere Bilder gut funktioniert.\n",
    "\n",
    "Zunächst wird das Modell in den Evaluierungsmodus versetzt. In diesem Modus sind Schichten wie Dropout deaktiviert und Batch-Normalisierung verwendet gespeicherte Mittelwerte und Varianzen, statt sie neu aus den aktuellen Eingaben zu berechnen. Dadurch wird ein konsistentes Verhalten des Modells während der Auswertung sichergestellt.\n",
    "\n",
    "Im nächsten Schritt wird die Berechnung von Gradienten ausgeschaltet. Das spart Speicher und beschleunigt die Ausführung, da beim Testen keine Gewichtsaktualisierungen notwendig sind.\n",
    "\n",
    "Für jedes Bildpaar im Validierungsdatensatz werden dann folgende Schritte durchgeführt:  \n",
    "- Die Eingabebilder und die zugehörigen Labels werden auf das passende Gerät geladen (CPU, GPU oder MPS).  \n",
    "- Das Modell berechnet Vorhersagen (Wahrscheinlichkeiten für alle Klassen).  \n",
    "- Die Klasse mit der höchsten Wahrscheinlichkeit wird als Vorhersage gewählt.  \n",
    "- Diese Vorhersage wird mit dem tatsächlichen Label verglichen. Wenn die Vorhersage korrekt ist, wird ein Zähler für richtige Ergebnisse erhöht.\n",
    "\n",
    "Am Ende der Schleife wird die Gesamtzahl der korrekten Vorhersagen durch die Gesamtzahl der Bilder geteilt und mit 100 multipliziert. Das Ergebnis ist die Genauigkeit in Prozent.  \n",
    "\n",
    "Diese Genauigkeit ist eine wichtige Kennzahl:  \n",
    " - Sie zeigt, wie gut das Modell verallgemeinert und nicht nur die Trainingsdaten „auswendig gelernt“ hat.  \n",
    " - Eine hohe Genauigkeit deutet darauf hin, dass das Modell die zugrunde liegenden Muster der Bilder erkannt hat und erfolgreich neue Bilder klassifizieren kann."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "K3m22Cl9qoV4",
   "metadata": {
    "id": "K3m22Cl9qoV4"
   },
   "source": [
    "## Klassifizierung eines Bildes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "x8nhUdF-quRq",
   "metadata": {
    "id": "x8nhUdF-quRq"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def classify_image(image, model, class_names, device):\n",
    "    # Transform must match training preprocessing\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "    ])\n",
    "\n",
    "    # Load and preprocess image\n",
    "\n",
    "    image = transform(image).unsqueeze(0).to(device)  # add batch dimension\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "\n",
    "    return class_names[predicted.item()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3c293b",
   "metadata": {},
   "source": [
    "# Erklärung der Einzelbildklassifikation (Inference)\n",
    "\n",
    "Nachdem das Modell trainiert und evaluiert wurde, kann es verwendet werden, um neue, einzelne Bilder zu klassifizieren.  \n",
    "Dafür wird eine spezielle Funktion definiert, die ein Bild als Eingabe nimmt und eine Vorhersage zurückgibt.\n",
    "\n",
    "Zuerst muss das Eingabebild vorverarbeitet werden, um es in das Format zu bringen, das das Modell erwartet:  \n",
    "- Die Bildgröße wird auf die während des Trainings genutzte Größe (z.B. 128x128 Pixel) skaliert.  \n",
    "- Das Bild wird in einen Tensor umgewandelt, das heißt, es wird in eine numerische Matrix konvertiert, die vom Modell verarbeitet werden kann.  \n",
    "- Die Pixelwerte werden normalisiert, sodass sie in einem bestimmten Wertebereich liegen (z.B. zwischen -1 und 1). Diese Normalisierung entspricht genau der, die auch während des Trainings angewandt wurde, um Konsistenz sicherzustellen.\n",
    "\n",
    "Anschließend wird dem Tensor eine zusätzliche Dimension hinzugefügt, um die Batch-Größe darzustellen – auch wenn nur ein einzelnes Bild klassifiziert wird, erwartet das Modell eine Batch-Struktur.\n",
    "\n",
    "Das Modell wird in den Evaluierungsmodus versetzt, damit keine Trainings-spezifischen Operationen (wie Dropout) aktiv sind. Innerhalb eines Kontextes, der die Berechnung von Gradienten deaktiviert (für Effizienz und Speicherersparnis), wird das Bild durch das Modell geführt und eine Vorhersage erzeugt.\n",
    "\n",
    "Die Vorhersage besteht aus Wahrscheinlichkeiten für jede mögliche Klasse. Die Klasse mit der höchsten Wahrscheinlichkeit wird als Ergebnis der Klassifikation ausgewählt.\n",
    "\n",
    "Abschließend gibt die Funktion den Namen der vorhergesagten Klasse zurück, sodass der Benutzer direkt erkennen kann, zu welcher Tierklasse das Bild gehört.\n",
    "\n",
    "Diese Vorgehensweise ermöglicht es, das trainierte Modell praktisch einzusetzen, um einzelne Bilder schnell und zuverlässig zu klassifizieren.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "wZqRkx_OrTrG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wZqRkx_OrTrG",
    "outputId": "4a091654-7d8f-49a3-b5a2-c61fe4ce048b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: dog\n"
     ]
    }
   ],
   "source": [
    "image_path = os.path.join(path2, 'animals/val/dog/dog117.jpg')\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "result = classify_image(image, model, classes, device)\n",
    "print(\"Predicted class:\", result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f31588f",
   "metadata": {},
   "source": [
    "# Erklärung der Beispielanwendung zur Bildklassifikation\n",
    "\n",
    "Um die zuvor definierte Klassifikationsfunktion zu testen, wird ein konkretes Beispielbild verwendet.  \n",
    "\n",
    "Zunächst wird der Pfad zu einem Bild festgelegt, das klassifiziert werden soll. In diesem Fall handelt es sich um ein Bild aus dem Validierungsdatensatz, das einen Hund zeigt.\n",
    "\n",
    "Das Bild wird mit der Bibliothek PIL (Python Imaging Library) geöffnet und in den RGB-Farbmodus konvertiert. Dies stellt sicher, dass das Bild drei Farbkanäle besitzt, wie es das Modell erwartet.\n",
    "\n",
    "Anschließend wird die Klassifikationsfunktion aufgerufen und das geladene Bild zusammen mit dem trainierten Modell, den Klassennamen und dem verwendeten Gerät (CPU, GPU oder MPS) übergeben.\n",
    "\n",
    "Die Funktion gibt die vorhergesagte Klasse zurück, die dann in der Konsole ausgegeben wird.\n",
    "\n",
    "Diese Vorgehensweise demonstriert, wie das trainierte Modell praktisch angewendet werden kann, um einzelne Bilder zu klassifizieren. Durch das Ändern des Bildpfads kann diese Methode flexibel auf beliebige Bilder angewendet werden.\n",
    "\n",
    "Dies ist ein wichtiger Schritt, um die praktische Tauglichkeit des Modells zu überprüfen und es in realen Anwendungen einzusetzen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecce0fdb",
   "metadata": {},
   "source": [
    "# Persönliches Fazit\n",
    "\n",
    "## Vorgehen\n",
    "- Projekt entschieden --> Klassifizierung\n",
    "- Datensätze herausgesucht\n",
    "- Schrittweise Programm aufgebaut:\n",
    "    - datensatz importiert/eingebunden\n",
    "    - Daten vorbereitet\n",
    "    - KI-Model aufgebaut\n",
    "    - KI mit Trainingsdaten trainiert\n",
    "    - Evaluation der KI\n",
    "- Testing \n",
    "\n",
    "\n",
    "## Hindernisse\n",
    "- Da erstes KI-Projekt neues Umfeld --> viel einlesen und neue unbekannte Umgebungen\n",
    "- Probleme bei der Nutzung von Tensorflow --> wechsel auf Pytorch\n",
    "- Zu wenig Leistung durch CPU Verwendung -> lange Laufzeiten\n",
    "--> Konnten über GoogleColab schließlich die GPU verwenden\n",
    "\n",
    "## Learnings\n",
    "- Erste KI-Erfahrung --> Grundlage für zukünftige Projekte\n",
    "- Einarbeitung in JupyterNotebook\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
